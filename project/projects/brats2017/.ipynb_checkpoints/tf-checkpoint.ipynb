{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", reshape=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img_size = (28, 28)\n",
    "n_classes = 10\n",
    "\n",
    "imgs_train = mnist.train.images.reshape((-1, 1, *img_size)) / 255\n",
    "imgs_val = mnist.validation.images.reshape((-1, 1, *img_size)) / 255\n",
    "imgs_test = mnist.test.images.reshape((-1, 1, *img_size)) / 255\n",
    "\n",
    "y_train = mnist.train.labels.astype(np.int32)\n",
    "y_val = mnist.validation.labels.astype(np.int32)\n",
    "y_test = mnist.test.labels.astype(np.int32)\n",
    "\n",
    "def make_batch_iter(x, y, batch_size, shuffle=False):\n",
    "    n = len(x)\n",
    "    idx = np.arange(n)\n",
    "    if shuffle:\n",
    "        np.random.shuffle(idx)\n",
    "    \n",
    "    for i in range(0, n, batch_size):\n",
    "        x_batch = x[i:i+batch_size]\n",
    "        y_batch = y[i:i+batch_size]\n",
    "        yield np.array(x_batch, np.float32), np.array(y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_fe(l, n_layers, kernel_size, n_chans_base, n_chans_mul):\n",
    "    for i in range(n_layers):\n",
    "        n_chans = n_chans_base * n_chans_mul ** i\n",
    "        l = slim.conv2d(l, n_chans, kernel_size, padding='valid',\n",
    "                        data_format='NCHW', activation_fn=tf.nn.relu,\n",
    "                        normalizer_fn=slim.batch_norm)\n",
    "        l = slim.max_pool2d(l, 2, 2, data_format='NCHW')\n",
    "    l = tf.reduce_mean(l, axis=(2, 3), name='global_average_pooling')\n",
    "    return l\n",
    "\n",
    "def build_clf(l):\n",
    "    n_layers = 2\n",
    "    units = 1024\n",
    "    for i in range(n_layers):\n",
    "        l = slim.relu(l, units, normalizer_fn=slim.batch_norm)\n",
    "    l = slim.fully_connected(l, n_classes, normalizer_fn=slim.batch_norm)\n",
    "    return l\n",
    "\n",
    "class Model:\n",
    "    def __init__(self, n_layers, n_chans_base, n_chans_mul, kernel_size):\n",
    "        self.x_ph = tf.placeholder(tf.float32, (None, 1, *img_size))\n",
    "        self.training = tf.placeholder(tf.bool)\n",
    "        self.y_ph = tf.placeholder(tf.int64, (None,))\n",
    "        \n",
    "        with slim.arg_scope([slim.batch_norm], is_training=self.training,\n",
    "                            decay=0.9, data_format='NCHW', fused=True):\n",
    "            self.fe = build_fe(self.x_ph, n_layers, kernel_size,\n",
    "                               n_chans_base, n_chans_mul)\n",
    "            self.logits = build_clf(self.fe)\n",
    "        \n",
    "        self.loss = tf.reduce_mean(tf.losses.sparse_softmax_cross_entropy(self.y_ph, self.logits))\n",
    "        self.acc = tf.contrib.metrics.accuracy(tf.argmax(self.logits, 1), self.y_ph)\n",
    "        \n",
    "        self.train_op = slim.learning.create_train_op(self.loss, tf.train.AdamOptimizer())\n",
    "\n",
    "n_layers = 3\n",
    "kernel_size = 3\n",
    "n_chans_base = 16\n",
    "n_chans_mul = 2\n",
    "\n",
    "tf.reset_default_graph()\n",
    "graph = tf.get_default_graph()\n",
    "with graph.as_default():\n",
    "    model = Model(n_layers, n_chans_base, n_chans_mul, kernel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "Train: 0.686799747875 0.908981819491\n",
      "Val  : 2.35941520271 0.112600002193\n",
      "Time : 2.4215240478515625\n",
      "\n",
      "\n",
      "Epoch 1\n",
      "Train: 0.473614842718 0.97070909221\n",
      "Val  : 0.475247860146 0.976400008774\n",
      "Time : 1.4448506832122803\n",
      "\n",
      "\n",
      "Epoch 2\n",
      "Train: 0.421291642683 0.980254545663\n",
      "Val  : 0.432654821301 0.981199994373\n",
      "Time : 1.4468259811401367\n",
      "\n",
      "\n",
      "Epoch 3\n",
      "Train: 0.387854342539 0.985163636277\n",
      "Val  : 0.403738159609 0.983199998665\n",
      "Time : 1.4462215900421143\n",
      "\n",
      "\n",
      "Epoch 4\n",
      "Train: 0.362876089621 0.988000000503\n",
      "Val  : 0.376130448675 0.983599995804\n",
      "Time : 1.4481439590454102\n",
      "\n",
      "\n",
      "Epoch 5\n",
      "Train: 0.343697600499 0.990200000598\n",
      "Val  : 0.34799063096 0.984799997234\n",
      "Time : 1.445805311203003\n",
      "\n",
      "\n",
      "Epoch 6\n",
      "Train: 0.329198759452 0.991909091507\n",
      "Val  : 0.338924485779 0.984399987888\n",
      "Time : 1.4417996406555176\n",
      "\n",
      "\n",
      "Epoch 7\n",
      "Train: 0.318571049447 0.993527273325\n",
      "Val  : 0.329607893515 0.984799979973\n",
      "Time : 1.4463655948638916\n",
      "\n",
      "\n",
      "Epoch 8\n",
      "Train: 0.311607101081 0.994418182416\n",
      "Val  : 0.327740947485 0.98479999218\n",
      "Time : 1.4393110275268555\n",
      "\n",
      "\n",
      "Epoch 9\n",
      "Train: 0.306597119245 0.995418182416\n",
      "Val  : 0.325956476212 0.98459999218\n",
      "Time : 1.445904016494751\n",
      "\n",
      "\n",
      "Epoch 10\n",
      "Train: 0.30276286498 0.996527272632\n",
      "Val  : 0.323402677059 0.98439999218\n",
      "Time : 1.4460082054138184\n",
      "\n",
      "\n",
      "Epoch 11\n",
      "Train: 0.299677888996 0.997272726388\n",
      "Val  : 0.323604334688 0.984599982834\n",
      "Time : 1.4494504928588867\n",
      "\n",
      "\n",
      "Epoch 12\n",
      "Train: 0.297412321169 0.997836363836\n",
      "Val  : 0.322063477516 0.98399999218\n",
      "Time : 1.4364619255065918\n",
      "\n",
      "\n",
      "Epoch 13\n",
      "Train: 0.295689988175 0.998327272927\n",
      "Val  : 0.325555675983 0.98379999361\n",
      "Time : 1.4401438236236572\n",
      "\n",
      "\n",
      "Epoch 14\n",
      "Train: 0.294230245126 0.998709091897\n",
      "Val  : 0.323530183601 0.983199981403\n",
      "Time : 1.4402403831481934\n",
      "\n",
      "\n",
      "Epoch 15\n",
      "Train: 0.293202001511 0.998909091897\n",
      "Val  : 0.325885425186 0.983599984264\n",
      "Time : 1.4510281085968018\n",
      "\n",
      "\n",
      "Epoch 16\n",
      "Train: 0.291931306787 0.999090909585\n",
      "Val  : 0.324715205002 0.983999982834\n",
      "Time : 1.4413001537322998\n",
      "\n",
      "\n",
      "Epoch 17\n",
      "Train: 0.290561869058 0.999309090614\n",
      "Val  : 0.326481669712 0.984599984264\n",
      "Time : 1.440751075744629\n",
      "\n",
      "\n",
      "Epoch 18\n",
      "Train: 0.289718024787 0.999363636858\n",
      "Val  : 0.323508019733 0.986199977779\n",
      "Time : 1.4437203407287598\n",
      "\n",
      "\n",
      "Epoch 19\n",
      "Train: 0.288868908319 0.999472727767\n",
      "Val  : 0.320671971607 0.987399989986\n",
      "Time : 1.4488959312438965\n",
      "\n",
      "\n",
      "Epoch 20\n",
      "Train: 0.288155024784 0.999581817887\n",
      "Val  : 0.318027120543 0.987199977779\n",
      "Time : 1.4451186656951904\n",
      "\n",
      "\n",
      "Epoch 21\n",
      "Train: 0.287571504094 0.999618182312\n",
      "Val  : 0.313517412519 0.986199988556\n",
      "Time : 1.442613124847412\n",
      "\n",
      "\n",
      "Epoch 22\n",
      "Train: 0.287135534711 0.999763636858\n",
      "Val  : 0.310896576929 0.985999987125\n",
      "Time : 1.4445750713348389\n",
      "\n",
      "\n",
      "Epoch 23\n",
      "Train: 0.286681885875 0.999781818676\n",
      "Val  : 0.312877655792 0.984599985695\n",
      "Time : 1.445519208908081\n",
      "\n",
      "\n",
      "Epoch 24\n",
      "Train: 0.286315472239 0.999800000494\n",
      "Val  : 0.31638978734 0.983400002956\n",
      "Time : 1.4443233013153076\n",
      "\n",
      "\n",
      "Epoch 25\n",
      "Train: 0.285981873222 0.999818182312\n",
      "Val  : 0.318896380377 0.983000001526\n",
      "Time : 1.4371592998504639\n",
      "\n",
      "\n",
      "Epoch 26\n",
      "Train: 0.285807735898 0.999818182312\n",
      "Val  : 0.319337441254 0.981599998665\n",
      "Time : 1.4428596496582031\n",
      "\n",
      "\n",
      "Epoch 27\n",
      "Train: 0.2855898647 0.999854545949\n",
      "Val  : 0.313212083578 0.981599989319\n",
      "Time : 1.4448001384735107\n",
      "\n",
      "\n",
      "Epoch 28\n",
      "Train: 0.285387887686 0.999872726978\n",
      "Val  : 0.307066595125 0.98339999218\n",
      "Time : 1.444246530532837\n",
      "\n",
      "\n",
      "Epoch 29\n",
      "Train: 0.285126182253 0.999872727767\n",
      "Val  : 0.306428307199 0.985799984264\n",
      "Time : 1.4407727718353271\n",
      "\n",
      "\n",
      "Epoch 30\n",
      "Train: 0.284990268061 0.999872727767\n",
      "Val  : 0.305302021933 0.987199974918\n",
      "Time : 1.4426791667938232\n",
      "\n",
      "\n",
      "Epoch 31\n",
      "Train: 0.28511962181 0.999890909585\n",
      "Val  : 0.304289277172 0.986599985695\n",
      "Time : 1.444101333618164\n",
      "\n",
      "\n",
      "Epoch 32\n",
      "Train: 0.285074770099 0.999890909585\n",
      "Val  : 0.307297383404 0.986799987125\n",
      "Time : 1.4516618251800537\n",
      "\n",
      "\n",
      "Epoch 33\n",
      "Train: 0.284900625454 0.999872726978\n",
      "Val  : 0.306400122261 0.986599977779\n",
      "Time : 1.445225477218628\n",
      "\n",
      "\n",
      "Epoch 34\n",
      "Train: 0.284670902317 0.999890909585\n",
      "Val  : 0.308935612822 0.986399988556\n",
      "Time : 1.4381604194641113\n",
      "\n",
      "\n",
      "Epoch 35\n",
      "Train: 0.28428922775 0.999890908796\n",
      "Val  : 0.310230985355 0.986599987125\n",
      "Time : 1.4448275566101074\n",
      "\n",
      "\n",
      "Epoch 36\n",
      "Train: 0.283768907755 0.999909091403\n",
      "Val  : 0.318271056366 0.986199982834\n",
      "Time : 1.4434223175048828\n",
      "\n",
      "\n",
      "Epoch 37\n",
      "Train: 0.283464183426 0.999909091403\n",
      "Val  : 0.32124504323 0.98579999218\n",
      "Time : 1.4509093761444092\n",
      "\n",
      "\n",
      "Epoch 38\n",
      "Train: 0.283161109417 0.999909091403\n",
      "Val  : 0.318114835978 0.986199982834\n",
      "Time : 1.4431865215301514\n",
      "\n",
      "\n",
      "Epoch 39\n",
      "Train: 0.282926918342 0.999909090614\n",
      "Val  : 0.31693847599 0.986199972057\n",
      "Time : 1.4441308975219727\n",
      "\n",
      "\n",
      "Epoch 40\n",
      "Train: 0.282725162467 0.999909091403\n",
      "Val  : 0.318488272715 0.98639999218\n",
      "Time : 1.440091609954834\n",
      "\n",
      "\n",
      "Epoch 41\n",
      "Train: 0.282588456219 0.999909091403\n",
      "Val  : 0.319611177111 0.985799987888\n",
      "Time : 1.4416110515594482\n",
      "\n",
      "\n",
      "Epoch 42\n",
      "Train: 0.282479960168 0.999909091403\n",
      "Val  : 0.318789258862 0.985999989319\n",
      "Time : 1.4330945014953613\n",
      "\n",
      "\n",
      "Epoch 43\n",
      "Train: 0.282372603794 0.999927272727\n",
      "Val  : 0.315151998425 0.985999989319\n",
      "Time : 1.4423840045928955\n",
      "\n",
      "\n",
      "Epoch 44\n",
      "Train: 0.282283884417 0.999927272727\n",
      "Val  : 0.312256931639 0.985199977112\n",
      "Time : 1.4399762153625488\n",
      "\n",
      "\n",
      "Epoch 45\n",
      "Train: 0.282192521325 0.999927272727\n",
      "Val  : 0.312843840265 0.986199982834\n",
      "Time : 1.4454288482666016\n",
      "\n",
      "\n",
      "Epoch 46\n",
      "Train: 0.282081964575 0.999927272727\n",
      "Val  : 0.31559384346 0.98659999218\n",
      "Time : 1.437467336654663\n",
      "\n",
      "\n",
      "Epoch 47\n",
      "Train: 0.282012226872 0.999945454545\n",
      "Val  : 0.318021756601 0.987599974918\n",
      "Time : 1.4473035335540771\n",
      "\n",
      "\n",
      "Epoch 48\n",
      "Train: 0.281957581299 0.999945454545\n",
      "Val  : 0.319543051958 0.987599987125\n",
      "Time : 1.4418458938598633\n",
      "\n",
      "\n",
      "Epoch 49\n",
      "Train: 0.281928672448 0.999945454545\n",
      "Val  : 0.320246087551 0.986999984264\n",
      "Time : 1.4389803409576416\n",
      "\n",
      "\n",
      "Epoch 50\n",
      "Train: 0.281929502262 0.999945454545\n",
      "Val  : 0.320107395124 0.986799984264\n",
      "Time : 1.4390835762023926\n",
      "\n",
      "\n",
      "Epoch 51\n",
      "Train: 0.281926452602 0.999945454545\n",
      "Val  : 0.320450112295 0.986999987125\n",
      "Time : 1.4399540424346924\n",
      "\n",
      "\n",
      "Epoch 52\n",
      "Train: 0.281899104179 0.999945454545\n",
      "Val  : 0.320969536924 0.986599974918\n",
      "Time : 1.4411637783050537\n",
      "\n",
      "\n",
      "Epoch 53\n",
      "Train: 0.281863196117 0.999963636364\n",
      "Val  : 0.321460341311 0.986799974918\n",
      "Time : 1.443995475769043\n",
      "\n",
      "\n",
      "Epoch 54\n",
      "Train: 0.281796682895 0.999963636364\n",
      "Val  : 0.320608905411 0.986599987125\n",
      "Time : 1.4464244842529297\n",
      "\n",
      "\n",
      "Epoch 55\n",
      "Train: 0.281775447143 0.999963636364\n",
      "Val  : 0.319212759018 0.986399985695\n",
      "Time : 1.4461445808410645\n",
      "\n",
      "\n",
      "Epoch 56\n",
      "Train: 0.281779028992 0.999963636364\n",
      "Val  : 0.317444116879 0.986399985695\n",
      "Time : 1.4447293281555176\n",
      "\n",
      "\n",
      "Epoch 57\n",
      "Train: 0.281788544438 0.999963636364\n",
      "Val  : 0.31660536356 0.985999974918\n",
      "Time : 1.446286916732788\n",
      "\n",
      "\n",
      "Epoch 58\n",
      "Train: 0.28180771086 0.999963636364\n",
      "Val  : 0.315119451141 0.986199985695\n",
      "Time : 1.4415104389190674\n",
      "\n",
      "\n",
      "Epoch 59\n",
      "Train: 0.28182614564 0.999963636364\n",
      "Val  : 0.31348933053 0.986199985695\n",
      "Time : 1.4436109066009521\n",
      "\n",
      "\n",
      "Epoch 60\n",
      "Train: 0.281770992622 0.999963636364\n",
      "Val  : 0.313040714312 0.986599987125\n",
      "Time : 1.4404237270355225\n",
      "\n",
      "\n",
      "Epoch 61\n",
      "Train: 0.281721075054 0.999963636364\n",
      "Val  : 0.312996949053 0.986399985695\n",
      "Time : 1.4484162330627441\n",
      "\n",
      "\n",
      "Epoch 62\n",
      "Train: 0.281638672534 0.999963636364\n",
      "Val  : 0.314400635815 0.986599984264\n",
      "Time : 1.4391677379608154\n",
      "\n",
      "\n",
      "Epoch 63\n",
      "Train: 0.28153866516 0.999963636364\n",
      "Val  : 0.31392867775 0.986199982834\n",
      "Time : 1.4425475597381592\n",
      "\n",
      "\n",
      "Epoch 64\n",
      "Train: 0.281449750484 0.999963636364\n",
      "Val  : 0.31377849102 0.986799982834\n",
      "Time : 1.4392001628875732\n",
      "\n",
      "\n",
      "Epoch 65\n",
      "Train: 0.281384051973 0.999963636364\n",
      "Val  : 0.313938921499 0.987199985695\n",
      "Time : 1.44126558303833\n",
      "\n",
      "\n",
      "Epoch 66\n",
      "Train: 0.281331011737 0.999963636364\n",
      "Val  : 0.313995221043 0.986999985695\n",
      "Time : 1.4436876773834229\n",
      "\n",
      "\n",
      "Epoch 67\n",
      "Train: 0.281284827024 0.999963636364\n",
      "Val  : 0.314061863327 0.987199985695\n",
      "Time : 1.4417400360107422\n",
      "\n",
      "\n",
      "Epoch 68\n",
      "Train: 0.281261088562 0.999981818182\n",
      "Val  : 0.313311838722 0.986599985695\n",
      "Time : 1.442748785018921\n",
      "\n",
      "\n",
      "Epoch 69\n",
      "Train: 0.281236280294 0.999981818182\n",
      "Val  : 0.312127851295 0.98759997921\n",
      "Time : 1.4456806182861328\n",
      "\n",
      "\n",
      "Epoch 70\n",
      "Train: 0.281221139279 0.999981818182\n",
      "Val  : 0.308920073128 0.986999985695\n",
      "Time : 1.4409420490264893\n",
      "\n",
      "\n",
      "Epoch 71\n",
      "Train: 0.281209117599 0.999981818182\n",
      "Val  : 0.311657291651 0.986599985695\n",
      "Time : 1.4391698837280273\n",
      "\n",
      "\n",
      "Epoch 72\n",
      "Train: 0.281203502811 0.999981818182\n",
      "Val  : 0.316154927063 0.986799995041\n",
      "Time : 1.448002576828003\n",
      "\n",
      "\n",
      "Epoch 73\n",
      "Train: 0.281204616854 0.999981818182\n",
      "Val  : 0.314316291285 0.985999996471\n",
      "Time : 1.4422059059143066\n",
      "\n",
      "\n",
      "Epoch 74\n",
      "Train: 0.281219525584 0.999981818182\n",
      "Val  : 0.313302036858 0.987399974918\n",
      "Time : 1.4404373168945312\n",
      "\n",
      "\n",
      "Epoch 75\n",
      "Train: 0.281251519923 0.999981818182\n",
      "Val  : 0.310284069681 0.98559999218\n",
      "Time : 1.4419574737548828\n",
      "\n",
      "\n",
      "Epoch 76\n",
      "Train: 0.281247502396 0.999981818182\n",
      "Val  : 0.316647527027 0.986399974918\n",
      "Time : 1.4442155361175537\n",
      "\n",
      "\n",
      "Epoch 77\n",
      "Train: 0.281299130622 0.999981818182\n",
      "Val  : 0.321662522411 0.986799976349\n",
      "Time : 1.445572853088379\n",
      "\n",
      "\n",
      "Epoch 78\n",
      "Train: 0.28226614558 0.99985454516\n",
      "Val  : 0.352455143595 0.981199989319\n",
      "Time : 1.4407987594604492\n",
      "\n",
      "\n",
      "Epoch 79\n",
      "Train: 0.294146064212 0.997181817592\n",
      "Val  : 0.372752509117 0.980799979973\n",
      "Time : 1.4453186988830566\n",
      "\n",
      "\n",
      "Epoch 80\n",
      "Train: 0.29248300392 0.997490909585\n",
      "Val  : 0.312497297764 0.98519999361\n",
      "Time : 1.44248366355896\n",
      "\n",
      "\n",
      "Epoch 81\n",
      "Train: 0.285230523001 0.999618181523\n",
      "Val  : 0.31565667305 0.986799997902\n",
      "Time : 1.437830924987793\n",
      "\n",
      "\n",
      "Epoch 82\n",
      "Train: 0.282891159591 0.999890909091\n",
      "Val  : 0.315935774708 0.984999990749\n",
      "Time : 1.443366527557373\n",
      "\n",
      "\n",
      "Epoch 83\n",
      "Train: 0.281718786955 0.999963636364\n",
      "Val  : 0.316567595291 0.988399997902\n",
      "Time : 1.4398999214172363\n",
      "\n",
      "\n",
      "Epoch 84\n",
      "Train: 0.281242173351 0.999963636364\n",
      "Val  : 0.319434411573 0.988199987125\n",
      "Time : 1.441615104675293\n",
      "\n",
      "\n",
      "Epoch 85\n",
      "Train: 0.281061392437 0.999963636364\n",
      "Val  : 0.318815973091 0.987999976349\n",
      "Time : 1.433539867401123\n",
      "\n",
      "\n",
      "Epoch 86\n",
      "Train: 0.280965937831 0.999963636364\n",
      "Val  : 0.317484921885 0.987799976349\n",
      "Time : 1.4282622337341309\n",
      "\n",
      "\n",
      "Epoch 87\n",
      "Train: 0.280915526173 0.999963636364\n",
      "Val  : 0.316543088627 0.987599987125\n",
      "Time : 1.4450669288635254\n",
      "\n",
      "\n",
      "Epoch 88\n",
      "Train: 0.280889585946 0.999981818182\n",
      "Val  : 0.315919566441 0.987399987125\n",
      "Time : 1.4382131099700928\n",
      "\n",
      "\n",
      "Epoch 89\n",
      "Train: 0.280880369555 0.999981818182\n",
      "Val  : 0.315368214798 0.98819997921\n",
      "Time : 1.4461719989776611\n",
      "\n",
      "\n",
      "Epoch 90\n",
      "Train: 0.280894903712 0.999981818182\n",
      "Val  : 0.314531980658 0.987799977779\n",
      "Time : 1.438438892364502\n",
      "\n",
      "\n",
      "Epoch 91\n",
      "Train: 0.280955040021 1.0\n",
      "Val  : 0.314415973616 0.98799997921\n",
      "Time : 1.44382643699646\n",
      "\n",
      "\n",
      "Epoch 92\n",
      "Train: 0.280991199654 1.0\n",
      "Val  : 0.31490001092 0.987599987125\n",
      "Time : 1.4446427822113037\n",
      "\n",
      "\n",
      "Epoch 93\n",
      "Train: 0.280976079668 1.0\n",
      "Val  : 0.315045325518 0.987999988556\n",
      "Time : 1.441169023513794\n",
      "\n",
      "\n",
      "Epoch 94\n",
      "Train: 0.28092336972 1.0\n",
      "Val  : 0.315764997387 0.987799987125\n",
      "Time : 1.4402620792388916\n",
      "\n",
      "\n",
      "Epoch 95\n",
      "Train: 0.28088511558 1.0\n",
      "Val  : 0.31569001255 0.98819997921\n",
      "Time : 1.4430162906646729\n",
      "\n",
      "\n",
      "Epoch 96\n",
      "Train: 0.280864249862 1.0\n",
      "Val  : 0.316264351225 0.987799988556\n",
      "Time : 1.4422471523284912\n",
      "\n",
      "\n",
      "Epoch 97\n",
      "Train: 0.280842669682 1.0\n",
      "Val  : 0.316910072851 0.98839997921\n",
      "Time : 1.4413249492645264\n",
      "\n",
      "\n",
      "Epoch 98\n",
      "Train: 0.2808283172 1.0\n",
      "Val  : 0.317246486282 0.98839997921\n",
      "Time : 1.4471023082733154\n",
      "\n",
      "\n",
      "Epoch 99\n",
      "Train: 0.280794277789 1.0\n",
      "Val  : 0.317681902075 0.988199989986\n",
      "Time : 1.439817190170288\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_epoch = 100\n",
    "batch_size = 1024\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    for epoch in range(n_epoch):\n",
    "        train_iter = make_batch_iter(imgs_train, y_train, batch_size=batch_size)\n",
    "        val_iter = make_batch_iter(imgs_val, y_val, batch_size=batch_size)\n",
    "\n",
    "        start = time.time()\n",
    "\n",
    "        losses = []\n",
    "        weights = []\n",
    "        accs = []\n",
    "        for x_batch, y_batch in train_iter:\n",
    "            feed_dict = {model.x_ph: x_batch, model.y_ph: y_batch, model.training: True}\n",
    "            _, loss, acc = session.run([model.train_op, model.loss, model.acc], feed_dict)\n",
    "\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            weights.append(len(x_batch))\n",
    "\n",
    "        train_loss = np.average(np.array(losses).flatten(), weights=weights)\n",
    "        train_acc = np.average(np.array(accs).flatten(), weights=weights)\n",
    "\n",
    "        losses = []\n",
    "        weights = []\n",
    "        accs = []\n",
    "        for x_batch, y_batch in val_iter:\n",
    "            feed_dict = {model.x_ph: x_batch, model.y_ph: y_batch, model.training: False}\n",
    "            loss, acc = session.run([model.loss, model.acc], feed_dict)\n",
    "\n",
    "            accs.append(acc)\n",
    "            losses.append(loss)\n",
    "            weights.append(len(x_batch))\n",
    "\n",
    "        end = time.time()\n",
    "\n",
    "        val_loss = np.average(np.array(losses).flatten(), weights=weights)\n",
    "        val_acc = np.average(np.array(accs).flatten(), weights=weights)\n",
    "\n",
    "        print('Epoch {}'.format(epoch))\n",
    "        print('Train:', train_loss, train_acc)\n",
    "        print('Val  :', val_loss, val_acc)\n",
    "        print('Time :', end - start)\n",
    "        print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
